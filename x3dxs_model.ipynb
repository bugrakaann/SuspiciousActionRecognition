{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugrakaann/SuspiciousActionRecognition/blob/master/x3dxs_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!pip install pytorchvideo torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFgv3OC86_1G",
        "outputId": "1d8541a7-0400-42a6-91f4-8d4d585eec86"
      },
      "id": "WFgv3OC86_1G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorchvideo\n",
            "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting fvcore (from pytorchvideo)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av (from pytorchvideo)\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting parameterized (from pytorchvideo)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting iopath (from pytorchvideo)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (3.0.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Collecting portalocker (from iopath->pytorchvideo)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188686 sha256=13c72a5bacdcdf209cb564915d032aea384e5c8b797caf1a727139092e9c8280\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/6d/ae/d016375a73be141a0e11bb42289e2d0b046c35687fc8010ecc\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=4395f98995c371c26d26f8a952d53f3ae3f3d3d0ef06f014138feeff2ed7c0a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=0a0fd98b8c356ca4bdc9c1e333cf953ca228128a4ef785454e165847c4b5826a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, parameterized, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, av, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, nvidia-cusolver-cu12, fvcore, pytorchvideo\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed av-14.3.0 fvcore-0.1.5.post20221221 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 parameterized-0.9.0 portalocker-3.1.1 pytorchvideo-0.1.5 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:22.236707Z",
          "start_time": "2025-02-22T11:46:16.336297Z"
        },
        "id": "aea6d8027b7de87f"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np"
      ],
      "id": "aea6d8027b7de87f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T12:45:17.298142Z",
          "start_time": "2025-02-22T12:45:16.394712Z"
        },
        "id": "d450b013940b2438",
        "outputId": "2227a80b-ce15-46fc-d9c0-3c2f891cc630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "file_id = '1TNnf9zzoreiF7qaWZFjRXEDejThIbXJe'\n",
        "url = f\"https://drive.google.com/uc?export=download&confirm=t&id={file_id}\"\n",
        "\n",
        "# Dosyayı indir\n",
        "output_path = '/content/sample_data/dataset.zip'\n",
        "gdown.download(url, output_path, quiet=False)\n",
        "\n",
        "# Dosyayı unzip yap\n",
        "with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/sample_data')\n",
        "\n",
        "print(\"Dosya başarıyla indirildi ve çıkarıldı.\")"
      ],
      "id": "d450b013940b2438",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=t&id=1TNnf9zzoreiF7qaWZFjRXEDejThIbXJe\n",
            "To: /content/sample_data/dataset.zip\n",
            "100%|██████████| 10.3G/10.3G [02:33<00:00, 67.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dosya başarıyla indirildi ve çıkarıldı.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T12:45:17.315483800Z",
          "start_time": "2025-02-22T11:46:22.239686Z"
        },
        "id": "8be6ceab98346e92"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 🔥 Ana dataset klasörü\n",
        "dataset_path = \"/content/sample_data/dataset/Videos/Videos/\"\n",
        "\n",
        "# 📌 Normal ve Abnormal klasörlerini al\n",
        "normal_path = os.path.normpath(os.path.join(dataset_path, \"normal\"))\n",
        "abnormal_path = os.path.normpath(os.path.join(dataset_path, \"abnormal\"))\n",
        "\n",
        "# 📌 Tüm abnormal sınıfları al\n",
        "abnormal_classes = [folder for folder in os.listdir(abnormal_path) if os.path.isdir(os.path.join(abnormal_path, folder))]\n",
        "class_to_index = {cls: idx for idx, cls in enumerate(abnormal_classes, start=1)}  # 1, 2, 3... (Abnormal sınıflar)\n",
        "\n",
        "# 📌 DataFrame oluşturmak için liste\n",
        "data = []\n",
        "\n",
        "# ✅ Normal videolar (Binary = 0, Multi = -1)\n",
        "for subfolder in os.listdir(normal_path):\n",
        "    subfolder_path = os.path.normpath(os.path.join(normal_path, subfolder))\n",
        "\n",
        "    if os.path.isdir(subfolder_path):  # Eğer bir klasörse\n",
        "        videos = [\n",
        "            os.path.normpath(os.path.join(subfolder_path, v)).replace(\"\\\\\", \"/\")  # Windows uyumu için düzeltilmiş\n",
        "            for v in os.listdir(subfolder_path) if v.endswith(('.mp4', '.avi', '.mov'))\n",
        "        ]\n",
        "        for video in videos:\n",
        "            data.append((video, \"normal\", 0, -1))  # Binary label = 0, Multi label = -1 (yok)\n",
        "\n",
        "# ✅ Anormal videolar (Binary = 1, Multi = class index)\n",
        "for subfolder in abnormal_classes:\n",
        "    subfolder_path = os.path.normpath(os.path.join(abnormal_path, subfolder))\n",
        "\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # Rekürsif olarak tüm alt klasörleri gezer\n",
        "        for root, dirs, files in os.walk(subfolder_path):\n",
        "            for file in files:\n",
        "                if file.endswith(('.mp4', '.avi', '.mov')):\n",
        "                    video_path = os.path.normpath(os.path.join(root, file)).replace(\"\\\\\", \"/\")\n",
        "                    # Burada 'subfolder' en üst düzey klasör adını temsil eder;\n",
        "                    # eğer alt klasörlere göre farklı etiket atamak isterseniz, root veya dosya adını parse edebilirsiniz.\n",
        "                    data.append((video_path, subfolder, 1, class_to_index.get(subfolder, -1)))\n",
        "\n",
        "# 🔥 DataFrame oluştur\n",
        "df = pd.DataFrame(data, columns=[\"video_path\", \"category\", \"binary_label\", \"multi_label\"])\n"
      ],
      "id": "8be6ceab98346e92",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:22.392226Z",
          "start_time": "2025-02-22T11:46:22.382103Z"
        },
        "id": "ffc00782cc50e573",
        "outputId": "8c940fef-e659-47d5-82f0-098324430ee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2,stratify=df[\"binary_label\"],random_state=42)\n",
        "\n",
        "print(f\"Train set {len(train_df)} videos\")\n",
        "print(f\"Test set {len(test_df)} videos\")"
      ],
      "id": "ffc00782cc50e573",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set 2603 videos\n",
            "Test set 651 videos\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# GPU kullanımını kontrol et\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    print(\"GPU bulunuyor:\", physical_devices)\n",
        "else:\n",
        "    print(\"GPU bulunamadı.\")\n"
      ],
      "metadata": {
        "id": "xQH8ia_uBS1E",
        "outputId": "90426c38-a757-43df-a222-602aaeab4ff7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xQH8ia_uBS1E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU bulunuyor: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.15.0"
      ],
      "metadata": {
        "id": "wkpeQsHERg6u"
      },
      "id": "wkpeQsHERg6u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Reshape, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Tensorflow session'u temizle (önceki işlemlerden kalanları sıfırla)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# GPU kullanımını devre dışı bırakma\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, False)  # GPU'yu devre dışı bırakıyoruz\n",
        "        print(\"GPU devre dışı bırakıldı.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU ayarlanırken hata oluştu: {e}\")\n",
        "else:\n",
        "    print(\"GPU bulunamadı, CPU kullanılacak.\")\n",
        "\n",
        "# Tensorflow'un CUDA ile derlenip derlenmediğini ve fiziksel GPU olup olmadığını göster\n",
        "print(\"TensorFlow CUDA destekli mi?:\", tf.test.is_built_with_cuda())\n",
        "print(\"Fiziksel GPU var mı?:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "\n",
        "def build_autoencoder(input_shape):\n",
        "    # Input shape: (height, width, channels)\n",
        "    input_img = Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "    # Encoder kısmı\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Temporal özellikler için 1x1 konvolüsyon kullanın\n",
        "    temporal_features = Conv2D(16, (1, 1), activation='relu')(encoded)\n",
        "\n",
        "    # Decoder kısmı\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(temporal_features)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    # Çıkış - orijinal görüntüyü yeniden oluştur\n",
        "    decoded = Conv2D(input_shape[2], (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Model tanımı\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "# Frame yükleme fonksiyonu - GPU için optimize edilmiş\n",
        "def load_frames_from_videos(folder, target_size, frame_interval=30):\n",
        "    frames = []\n",
        "    valid_extensions = ('.mp4', '.avi', '.mkv')\n",
        "\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for filename in sorted(files):\n",
        "            if not filename.lower().endswith(valid_extensions):\n",
        "                continue\n",
        "\n",
        "            video_path = os.path.join(root, filename)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frame_idx = 0\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "            with tqdm(total=total_frames, desc=f\"İşleniyor: {filename}\", leave=False) as pbar:\n",
        "                while cap.isOpened():\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret:\n",
        "                        break\n",
        "\n",
        "                    if frame_idx % frame_interval == 0:\n",
        "                        frame_resized = cv2.resize(frame, target_size)\n",
        "                        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "                        frames.append(frame_rgb)\n",
        "\n",
        "                    frame_idx += 1\n",
        "                    pbar.update(1)\n",
        "\n",
        "            cap.release()\n",
        "            tqdm.write(f\"{filename} dosyasından {frame_idx // frame_interval} kare çekildi.\")\n",
        "\n",
        "    if len(frames) == 0:\n",
        "        raise ValueError(f\"'{folder}' klasöründe geçerli video dosyası bulunamadı.\")\n",
        "\n",
        "    # GPU için optimize edilmiş veri hazırlama\n",
        "    frames = np.stack(frames, axis=0).astype('float32') / 255.0\n",
        "    return frames\n",
        "\n",
        "\n",
        "# Eğitim fonksiyonu\n",
        "def train_autoencoder(normal_videos_folder, target_size=(128, 128), batch_size=32, epochs=50):\n",
        "    # Veri yükleme\n",
        "    print(\"Normal videolardan frame'ler yükleniyor...\")\n",
        "    normal_frames = load_frames_from_videos(normal_videos_folder, target_size)\n",
        "    print(f\"Toplam {len(normal_frames)} frame yüklendi.\")\n",
        "\n",
        "    # Model oluşturma\n",
        "    input_shape = (target_size[1], target_size[0], 3)\n",
        "    autoencoder = build_autoencoder(input_shape)\n",
        "    autoencoder.summary()\n",
        "\n",
        "    # ModelCheckpoint Callback\n",
        "    checkpoint_dir = '/content/drive/MyDrive/modelepochsaves/'\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-6\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_epoch_end=lambda epoch, logs: autoencoder.save(\n",
        "                f'{checkpoint_dir}autoencoder_epoch_{epoch+1}'  # Epoch sayısı eklenmiş dosya adı\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Eğitim\n",
        "    print(\"Autoencoder eğitimi başlıyor...\")\n",
        "    history = autoencoder.fit(\n",
        "        normal_frames, normal_frames,\n",
        "        validation_split=0.1,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return autoencoder, history\n",
        "\n",
        "\n",
        "# Eğitimi başlat\n",
        "normal_videos_folder = '/content/sample_data/dataset/Videos/Videos/normal'\n",
        "autoencoder, history = train_autoencoder(normal_videos_folder)\n",
        "\n",
        "# Eğitim sonuçlarını görselleştir\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Modeli kaydet\n",
        "autoencoder.save('/content/drive/MyDrive/modelepochsaves/autoencoder_final')\n",
        "print(\"Model kaydedildi: autoencoder_final.h5\")\n"
      ],
      "metadata": {
        "id": "sOc8Qm8MLzeJ",
        "outputId": "25a81fa7-d0b5-4253-9707-182c7fe23d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "sOc8Qm8MLzeJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU bulundu ve memory growth aktif: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow CUDA destekli mi?: True\n",
            "Fiziksel GPU var mı?: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow version: 2.18.0\n",
            "Num GPUs Available:  1\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "TensorFlow version: 2.18.0\n",
            "TensorFlow built with CUDA: True\n",
            "TensorFlow built with ROCm: False\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "CUDA support: True\n",
            "\n",
            "===== Nvidia-SMI Çıkışı =====\n",
            "Sun Apr 27 18:14:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0             30W /   70W |    4204MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "===== CUDA ve cuDNN Versiyonları =====\n",
            "CUDA Version: nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "cuDNN Version Info:\n",
            " #define CUDNN_MAJOR 9\n",
            "#define CUDNN_MINOR 2\n",
            "#define CUDNN_PATCHLEVEL 1\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 10000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "/* cannot use constexpr here since this is a C-only file */\n",
            "\n",
            "===== TensorFlow Build Info =====\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow.python.platform.build_info' has no attribute 'cuda_version_number'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1e62b05462b3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_info\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_build_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n===== TensorFlow Build Info =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA Version TF expects:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_build_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda_version_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuDNN Version TF expects:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_build_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_version_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.platform.build_info' has no attribute 'cuda_version_number'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "frame_transform = T.Compose([\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomRotation(degrees=(-10, 10)),\n",
        "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
        "    T.RandomApply([T.GaussianBlur(3)], p=0.3),\n",
        "    T.RandomApply([T.RandomGrayscale(p=0.2)], p=0.2),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "nTB7UP8sJxAq"
      },
      "id": "nTB7UP8sJxAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def frame_dropout(frames, p=0.2):\n",
        "    \"\"\"Belirli bir ihtimalle rastgele kareleri düşür.\"\"\"\n",
        "    keep_mask = torch.rand(len(frames)) > p\n",
        "    return frames[keep_mask] if keep_mask.sum() > 0 else frames\n",
        "\n",
        "def speed_perturbation(frames, min_speed=0.8, max_speed=1.2):\n",
        "    \"\"\"Videoyu rastgele hızlandır veya yavaşlat.\"\"\"\n",
        "    speed_factor = torch.FloatTensor(1).uniform_(min_speed, max_speed).item()\n",
        "    indices = torch.linspace(0, len(frames)-1, int(len(frames) * speed_factor)).long()\n",
        "    return frames[indices]"
      ],
      "metadata": {
        "id": "Ltf1G3_QJ6WJ"
      },
      "id": "Ltf1G3_QJ6WJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixes frame count after applying frame dropout at augmentation\n",
        "\n",
        "def fix_frame_count(frames, target_num_frames):\n",
        "    \"\"\"Frame sayısını sabitler: Eğer fazla ise kırpar, eksikse tekrarlar.\"\"\"\n",
        "    num_frames = frames.shape[0]  # Frame sayısını al\n",
        "\n",
        "    if num_frames > target_num_frames:\n",
        "        frames = frames[:target_num_frames]  # Fazla olanları kırp\n",
        "    elif num_frames < target_num_frames:\n",
        "        repeat_frames = target_num_frames - num_frames\n",
        "        last_frame = frames[-1].unsqueeze(0).repeat(repeat_frames, 1, 1, 1)  # Eksik frame'leri tekrar et\n",
        "        frames = torch.cat([frames, last_frame], dim=0)\n",
        "\n",
        "    return frames  # Her durumda (T, C, H, W) döner"
      ],
      "metadata": {
        "id": "Mc-L1wrgNvlu"
      },
      "id": "Mc-L1wrgNvlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:24.711059Z",
          "start_time": "2025-02-22T11:46:22.415593Z"
        },
        "id": "e0462ad59a40b35f"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, df, optical_flow_csv, num_frames=8, transform=None, resize_size=(192, 192), mode= \"train\"):\n",
        "        self.df = df\n",
        "        self.optical_flow_data = pd.read_csv(optical_flow_csv)  # 📌 Optical Flow verileri\n",
        "        self.num_frames = num_frames\n",
        "        self.transform = transform\n",
        "        self.resize_size = resize_size\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.df.iloc[idx][\"video_path\"]\n",
        "        binary_label = self.df.iloc[idx][\"binary_label\"]\n",
        "        multi_label = self.df.iloc[idx][\"multi_label\"]\n",
        "\n",
        "        if binary_label == 1:  # **Anormal Video**\n",
        "            # 📌 **Önceden hesaplanan en hareketli segmentleri al**\n",
        "            segments = eval(self.optical_flow_data[self.optical_flow_data[\"video_path\"] == video_path][\"top_segments\"].values[0])\n",
        "\n",
        "            # 📌 **Rastgele bir hareketli segment seç**\n",
        "            chosen_segment = random.choice(segments)\n",
        "\n",
        "            # 📌 **Seçili segmentin frame'lerini al**\n",
        "            frames = self.extract_frames(video_path, chosen_segment)\n",
        "\n",
        "        else:  # **Normal Video**\n",
        "            frames = self.extract_uniform_frames(video_path, self.num_frames)\n",
        "\n",
        "        frames = fix_frame_count(frames, self.num_frames)\n",
        "\n",
        "        #Eğer train setindeysek augmentation uygula\n",
        "        if self.mode == \"train\":\n",
        "            frames = frame_dropout(frames, p=0.1)\n",
        "            frames = speed_perturbation(frames, min_speed=0.8, max_speed=1.2)\n",
        "            frames = torch.stack([frame_transform(frame) for frame in frames])\n",
        "            frames = fix_frame_count(frames,self.num_frames)\n",
        "\n",
        "\n",
        "        # **🎯 GİRİŞ FORMATINI DÜZELTME**\n",
        "        frames = frames.permute(1, 0, 2, 3).contiguous()  # (T, C, H, W) → (C, T, H, W)\n",
        "\n",
        "        # Eğer transform varsa uygula\n",
        "        if self.transform:\n",
        "            frames = self.transform(frames)\n",
        "\n",
        "        return frames, torch.tensor(binary_label, dtype=torch.float32), torch.tensor(multi_label, dtype=torch.long)\n",
        "\n",
        "    def extract_frames(self, video_path, segment_index):\n",
        "        \"\"\"Anormal videolar için Optical Flow'a göre seçilen segmentten frame'leri çıkarır.\"\"\"\n",
        "        vr = torchvision.io.VideoReader(video_path, \"video\")\n",
        "        vr.set_current_stream(\"video\")\n",
        "\n",
        "        frames = []\n",
        "        frame_count = 0\n",
        "        start_frame = segment_index  # 📌 Seçilen hareketli segmentin başlangıcı\n",
        "        end_frame = start_frame + self.num_frames\n",
        "\n",
        "        for i, frame in enumerate(vr):\n",
        "            if i < start_frame:\n",
        "                continue  # 📌 Seçilen segmentin başlangıcına kadar frame'leri atla\n",
        "\n",
        "            if i >= end_frame:\n",
        "                break  # 📌 Seçilen segment tamamlandıktan sonra çık\n",
        "\n",
        "            frame = frame['data'].float() / 255.0  # Normalize (C, H, W)\n",
        "            frame = F.interpolate(frame.unsqueeze(0), size=self.resize_size, mode=\"bilinear\", align_corners=False)\n",
        "            frames.append(frame.squeeze(0))\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        return torch.stack(frames)  # (T, C, H, W) olarak döndür\n",
        "\n",
        "    def extract_uniform_frames(self, video_path, num_frames):\n",
        "        \"\"\"Normal videolar için eşit aralıklarla frame seçer.\"\"\"\n",
        "        vr = torchvision.io.VideoReader(video_path, \"video\")\n",
        "        vr.set_current_stream(\"video\")\n",
        "\n",
        "        frames = []\n",
        "        for frame in vr:\n",
        "            frame = frame['data'].float() / 255.0  # Normalize (C, H, W)\n",
        "            frame = F.interpolate(frame.unsqueeze(0), size=self.resize_size, mode=\"bilinear\", align_corners=False)\n",
        "            frames.append(frame.squeeze(0))\n",
        "\n",
        "        total_frames = len(frames)\n",
        "\n",
        "        # Eğer video kısa ise, son frame ile doldur\n",
        "        if total_frames < num_frames:\n",
        "            while len(frames) < num_frames:\n",
        "                frames.append(frames[-1].clone())\n",
        "        else:\n",
        "            # 📌 **Frame'leri eşit aralıklarla seç**\n",
        "            index_list = torch.linspace(0, total_frames - 1, num_frames).long()\n",
        "            frames = [frames[i] for i in index_list]\n",
        "\n",
        "        return torch.stack(frames)  # (T, C, H, W)"
      ],
      "id": "e0462ad59a40b35f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:24.722477Z",
          "start_time": "2025-02-22T11:46:24.711059Z"
        },
        "id": "22ce79d5c294f2c6",
        "outputId": "27785bf8-abe0-47b9-92a7-2b81b0041759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = VideoDataset(train_df, \"/content/drive/MyDrive/modelepochsaves/optical_flow_segments.csv\", num_frames=48, mode=\"train\")\n",
        "test_dataset = VideoDataset(test_df, \"/content/drive/MyDrive/modelepochsaves/optical_flow_segments.csv\", num_frames=48, mode=\"test\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "print(f\"Train loader {len(train_loader)} batches\")\n",
        "print(f\"Test loader {len(test_loader)} batches\")"
      ],
      "id": "22ce79d5c294f2c6",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader 326 batches\n",
            "Test loader 82 batches\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "49f69497b15dc01f"
      },
      "cell_type": "markdown",
      "source": [
        "X3D modelimizin output layerini tüm classlarımızı kapsayacak şekilde arttırmamız lazım\n",
        "Son katman ise ResNetBasicHead altında proj olarak tanımlanmış."
      ],
      "id": "49f69497b15dc01f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:26.156357Z",
          "start_time": "2025-02-22T11:46:24.736007Z"
        },
        "id": "eb2055b4174b845f",
        "outputId": "81c53360-6575-424a-c793-a5740c6e7008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "# ✅ X3D Modelini Yükleme\n",
        "model_name = \"x3d_s\"\n",
        "base_model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)\n",
        "\n",
        "# ✅ **Çıkış Katmanlarını Güncelle**\n",
        "in_features = base_model.blocks[-1].proj.out_features  # ✅ **Doğru çıkışı al!** (400 olmalı)\n",
        "\n",
        "binary_head = nn.Linear(2048, 1)  # Binary sınıflandırma için Sigmoid\n",
        "multi_head = nn.Linear(2048, len(train_df[\"multi_label\"].unique()))  # Multi-class sınıflandırma\n",
        "\n",
        "# ✅ **MultiTaskX3D Modeli**\n",
        "class MultiTaskX3D(nn.Module):\n",
        "    def __init__(self, base_model, binary_head, multi_head):\n",
        "        super(MultiTaskX3D, self).__init__()\n",
        "\n",
        "        # **Feature Extractor - Son bloğun içindeki ProjectedPool eklendi!**\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            *base_model.blocks[:-1],\n",
        "            base_model.blocks[-1].pool  # ✅ **Burada 400'e dönüşüm sağlandı!**\n",
        "        )\n",
        "\n",
        "        # **Global Average Pooling - Tüm boyutları 1x1x1'e düşürüyor!**\n",
        "        self.gap = nn.AdaptiveAvgPool3d(1)\n",
        "\n",
        "        # **Flatten**\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # **Çıkış Katmanları**\n",
        "        self.binary_head = binary_head\n",
        "        self.binary_activation = nn.Sigmoid()\n",
        "\n",
        "        self.multi_head = multi_head\n",
        "        self.multi_activation = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(f\"🚀 Model Girişi: {x.shape}\")\n",
        "\n",
        "        x = self.feature_extractor(x)\n",
        "        #print(f\"🟡 Feature Extractor Çıkışı: {x.shape}\")  # **(16, 400, 1, 1, 1) olmalı!**\n",
        "\n",
        "        x = self.gap(x)  # ✅ **GAP ile (16, 400, 1, 1, 1)**\n",
        "        #print(f\"🔵 GAP Sonrası Boyut: {x.shape}\")\n",
        "\n",
        "        x = self.flatten(x)  # ✅ **Artık (16, 400) olması lazım!**\n",
        "        #print(f\"🟢 Flatten Sonrası Boyut: {x.shape}\")\n",
        "\n",
        "        binary_out = self.binary_head(x)  # Binary sınıflandırma\n",
        "        multi_out = self.multi_activation(self.multi_head(x))  # Multi-class sınıflandırma\n",
        "\n",
        "        return binary_out, multi_out\n",
        "\n",
        "# ✅ Modeli başlat\n",
        "model = MultiTaskX3D(base_model, binary_head, multi_head)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"🚀 Model başarıyla yüklendi! Çalıştırılan cihaz: {device}\")"
      ],
      "id": "eb2055b4174b845f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/pytorchvideo/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/X3D_S.pyth\" to /root/.cache/torch/hub/checkpoints/X3D_S.pyth\n",
            "100%|██████████| 29.4M/29.4M [00:00<00:00, 38.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Model başarıyla yüklendi! Çalıştırılan cihaz: cuda\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cf0f8ab8e20aa3b7"
      },
      "cell_type": "markdown",
      "source": [
        "import torch\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "dummy_input = torch.randn(1, 3, 16, 160, 160)\n",
        "\n",
        "torch.onnx.export(model, dummy_input, \"x3d_xs.onnx\", opset_version=11\n",
        "                  ,do_constant_folding=True, input_names=[\"input\"], output_names=[\"output\"])"
      ],
      "id": "cf0f8ab8e20aa3b7"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self,inputs,targets):\n",
        "        ce_loss = F.cross_entropy(inputs,targets,reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return focal_loss.mean()"
      ],
      "metadata": {
        "id": "pZxmxvCalU2T"
      },
      "id": "pZxmxvCalU2T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T12:20:55.814874Z",
          "start_time": "2025-02-22T11:46:26.188132Z"
        },
        "id": "9b297db9945016d9",
        "outputId": "1ab45868-d72e-4e68-d1e3-69eae0ffe0e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "epoch_file_location = \"/content/drive/MyDrive/modelepochsaves\"\n",
        "\n",
        "# 🎯 Loss & Optimizer\n",
        "criterion_binary = nn.BCEWithLogitsLoss()  # Binary classification için\n",
        "criterion_multi = FocalLoss()  # Multi-class classification için\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-2)  # Weight decay ile overfitting azaltılır\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "# ⚡ AMP (Automatic Mixed Precision)\n",
        "scaler = torch.amp.GradScaler()\n",
        "\n",
        "# 🛑 Early Stopping Parametreleri\n",
        "patience = 3  # Kaç epoch boyunca iyileşme olmazsa durdursun\n",
        "min_delta = 0.01  # İyileşme için gereken minimum fark\n",
        "best_loss = float(\"inf\")  # En iyi validation loss başta sonsuz olarak ayarlanır\n",
        "counter = 0  # İyileşme olmayan epoch sayısı\n",
        "accuracy_threshold = 85.0  # Accuracy'nin geçmesi gereken eşik\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for epoch in range(40):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for videos, binary_labels, multi_labels in train_loader:\n",
        "        videos, binary_labels, multi_labels = (\n",
        "            videos.to(device),\n",
        "            binary_labels.to(device).float(),\n",
        "            multi_labels.to(device),\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(device):\n",
        "            binary_out, multi_out = model(videos)\n",
        "\n",
        "            # 🟢 Binary Classification Loss (Sigmoid)\n",
        "            binary_loss = criterion_binary(binary_out.squeeze(), binary_labels)\n",
        "\n",
        "            # 🔴 Multi-Class Classification Loss (Softmax) → Sadece anormal olanlara uygula\n",
        "            mask = (binary_labels == 1)\n",
        "            if mask.sum() > 0:\n",
        "                multi_loss = criterion_multi(multi_out[mask], multi_labels[mask])\n",
        "            else:\n",
        "                multi_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "            # ✅ Toplam loss hesapla (Binary + Multi)\n",
        "            total_loss = binary_loss + multi_loss\n",
        "\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += total_loss.item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # 📌 VALIDATION AŞAMASI\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_binary = 0\n",
        "    correct_multi = 0\n",
        "    total_binary = 0\n",
        "    total_multi = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for videos, binary_labels, multi_labels in test_loader:\n",
        "            videos, binary_labels, multi_labels = (\n",
        "                videos.to(device),\n",
        "                binary_labels.to(device).float(),\n",
        "                multi_labels.to(device),\n",
        "            )\n",
        "\n",
        "            binary_out, multi_out = model(videos)\n",
        "\n",
        "            # ✅ Binary Accuracy (Normal mi, Anormal mi?)\n",
        "            pred_binary = (binary_out.squeeze() > 0.5).long()\n",
        "            correct_binary += (pred_binary == binary_labels).sum().item()\n",
        "            total_binary += binary_labels.size(0)\n",
        "\n",
        "            # ✅ Multi-Class Accuracy (Eğer anormalse hangi sınıf?)\n",
        "            mask = (binary_labels == 1)\n",
        "            if mask.sum() > 0:\n",
        "                pred_multi = torch.argmax(multi_out[mask], dim=1)\n",
        "                correct_multi += (pred_multi == multi_labels[mask]).sum().item()\n",
        "                total_multi += multi_labels[mask].size(0)\n",
        "\n",
        "            # ✅ Validation loss hesapla\n",
        "            loss = criterion_binary(binary_out.squeeze(), binary_labels)\n",
        "            if total_multi > 0:\n",
        "                loss += criterion_multi(multi_out[mask], multi_labels[mask])\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    binary_acc = 100 * correct_binary / total_binary\n",
        "    multi_acc = 100 * correct_multi / total_multi if total_multi > 0 else 0\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} \"\n",
        "        f\"| Binary Acc: {binary_acc:.2f}% | Multi Acc: {multi_acc:.2f}%\"\n",
        "    )\n",
        "\n",
        "    # ✅ **Early Stopping (Binary Accuracy 85%'i geçmeli)**\n",
        "    if binary_acc >= accuracy_threshold:\n",
        "        if best_loss - val_loss > min_delta:\n",
        "            best_loss = val_loss\n",
        "            counter = 0\n",
        "            torch.save(model.state_dict(), f\"{epoch_file_location}/best_model_epoch_{epoch+1}.pth\")\n",
        "            print(f\"✅ Model kaydedildi: best_model_epoch_{epoch+1}.pth\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"❗ Early stopping counter: {counter}/{patience}\")\n",
        "\n",
        "        if counter >= patience:\n",
        "            print(\"⏹️ Early stopping triggered. Training stopped.\")\n",
        "            break\n",
        "    else:\n",
        "        print(f\"🚨 Accuracy {binary_acc:.2f}% < {accuracy_threshold}%, early stopping devre dışı!\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            },\n",
        "            f\"{epoch_file_location}/checkpoint_{epoch}.pth\",\n",
        "        )\n",
        "        print(f\"Model {epoch + 1} saved to checkpoint_{epoch + 1}.pth\")\n",
        "\n",
        "print(\"✅ Eğitim tamamlandı!\")"
      ],
      "id": "9b297db9945016d9",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.7108 | Val Loss: 0.7181 | Binary Acc: 60.06% | Multi Acc: 48.96%\n",
            "🚨 Accuracy 60.06% < 85.0%, early stopping devre dışı!\n",
            "Epoch 2 | Train Loss: 0.6038 | Val Loss: 0.7167 | Binary Acc: 56.07% | Multi Acc: 53.11%\n",
            "🚨 Accuracy 56.07% < 85.0%, early stopping devre dışı!\n",
            "Epoch 3 | Train Loss: 0.5089 | Val Loss: 0.7046 | Binary Acc: 54.99% | Multi Acc: 54.77%\n",
            "🚨 Accuracy 54.99% < 85.0%, early stopping devre dışı!\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}