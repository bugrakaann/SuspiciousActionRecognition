{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:46:22.236707Z",
     "start_time": "2025-02-22T11:46:16.336297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ],
   "id": "aea6d8027b7de87f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:45:17.298142Z",
     "start_time": "2025-02-22T12:45:16.394712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import zipfile\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip \"/content/drive/MyDrive/dataset.zip\" -d \"/content/sample_data\""
   ],
   "id": "d450b013940b2438",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mzipfile\u001B[39;00m\n\u001B[0;32m      4\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:45:17.315483800Z",
     "start_time": "2025-02-22T11:46:22.239686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ğŸ”¥ Ana dataset klasÃ¶rÃ¼\n",
    "dataset_path = \"/content/sample_data/dataset/Videos/Videos/\"\n",
    "\n",
    "# ğŸ“Œ Normal ve Abnormal klasÃ¶rlerini al\n",
    "normal_path = os.path.normpath(os.path.join(dataset_path, \"normal\"))\n",
    "abnormal_path = os.path.normpath(os.path.join(dataset_path, \"abnormal\"))\n",
    "\n",
    "# ğŸ“Œ TÃ¼m abnormal sÄ±nÄ±flarÄ± al\n",
    "abnormal_classes = [folder for folder in os.listdir(abnormal_path) if os.path.isdir(os.path.join(abnormal_path, folder))]\n",
    "class_to_index = {cls: idx for idx, cls in enumerate(abnormal_classes, start=1)}  # 1, 2, 3... (Abnormal sÄ±nÄ±flar)\n",
    "\n",
    "# ğŸ“Œ DataFrame oluÅŸturmak iÃ§in liste\n",
    "data = []\n",
    "\n",
    "# âœ… Normal videolar (Binary = 0, Multi = -1)\n",
    "for subfolder in os.listdir(normal_path):\n",
    "    subfolder_path = os.path.normpath(os.path.join(normal_path, subfolder))\n",
    "\n",
    "    if os.path.isdir(subfolder_path):  # EÄŸer bir klasÃ¶rse\n",
    "        videos = [\n",
    "            os.path.normpath(os.path.join(subfolder_path, v)).replace(\"\\\\\", \"/\")  # Windows uyumu iÃ§in dÃ¼zeltilmiÅŸ\n",
    "            for v in os.listdir(subfolder_path) if v.endswith(('.mp4', '.avi', '.mov'))\n",
    "        ]\n",
    "        for video in videos:\n",
    "            data.append((video, \"normal\", 0, -1))  # Binary label = 0, Multi label = -1 (yok)\n",
    "\n",
    "# âœ… Anormal videolar (Binary = 1, Multi = class index)\n",
    "for subfolder in abnormal_classes:\n",
    "    subfolder_path = os.path.normpath(os.path.join(abnormal_path, subfolder))\n",
    "\n",
    "    if os.path.isdir(subfolder_path):  # EÄŸer bir klasÃ¶rse\n",
    "        videos = [\n",
    "            os.path.normpath(os.path.join(subfolder_path, v)).replace(\"\\\\\", \"/\")  # Windows uyumu iÃ§in dÃ¼zeltilmiÅŸ\n",
    "            for v in os.listdir(subfolder_path) if v.endswith(('.mp4', '.avi', '.mov'))\n",
    "        ]\n",
    "        for video in videos:\n",
    "            data.append((video, subfolder, 1, class_to_index.get(subfolder, -1)))  # Binary label = 1, Multi label = class index\n",
    "\n",
    "# ğŸ”¥ DataFrame oluÅŸtur\n",
    "df = pd.DataFrame(data, columns=[\"video_path\", \"category\", \"binary_label\", \"multi_label\"])\n"
   ],
   "id": "8be6ceab98346e92",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:46:22.392226Z",
     "start_time": "2025-02-22T11:46:22.382103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2,stratify=df[\"binary_label\"],random_state=42)\n",
    "\n",
    "print(f\"Train set {len(train_df)} videos\")\n",
    "print(f\"Test set {len(test_df)} videos\")"
   ],
   "id": "ffc00782cc50e573",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 2224 videos\n",
      "Test set 556 videos\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Buraya preprocessing adÄ±mÄ± olarak Veri dÃ¶ndÃ¼rme, zoomout, kontrast vs eklenebilir",
   "id": "4eaf976d1250862b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:46:24.711059Z",
     "start_time": "2025-02-22T11:46:22.415593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, df, num_frames=8, transform=None, resize_size=(192, 192)):\n",
    "        self.df = df\n",
    "        self.num_frames = num_frames\n",
    "        self.transform = transform\n",
    "        self.resize_size = resize_size  # Sabit video boyutu (H, W)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.df.iloc[idx][\"video_path\"]\n",
    "        binary_label = self.df.iloc[idx][\"binary_label\"]\n",
    "        multi_label = self.df.iloc[idx][\"multi_label\"]\n",
    "\n",
    "        # ğŸ¥ Video'dan frame'leri oku\n",
    "        frames = self.extract_frames(video_path, self.num_frames)\n",
    "\n",
    "        #print(f\"ğŸ“Œ Ä°lk Frame Boyutu (T, C, H, W): {frames.shape}\")\n",
    "\n",
    "        # **ğŸ¯ GÄ°RÄ°Å FORMATINI DÃœZELTME**\n",
    "        frames = frames.permute(1, 0, 2, 3).contiguous()  # (T, C, H, W) â†’ (C, T, H, W)\n",
    "        #print(f\"âœ… Permute SonrasÄ± Boyut (C, T, H, W): {frames.shape}\")\n",
    "\n",
    "        # EÄŸer transform varsa uygula\n",
    "        if self.transform:\n",
    "            frames = self.transform(frames)\n",
    "\n",
    "        return frames, torch.tensor(binary_label, dtype=torch.float32), torch.tensor(multi_label, dtype=torch.long)\n",
    "\n",
    "    def extract_frames(self, video_path, num_frames):\n",
    "        vr = torchvision.io.VideoReader(video_path, \"video\")\n",
    "        vr.set_current_stream(\"video\")\n",
    "\n",
    "        frames = []\n",
    "        for frame in vr:\n",
    "            frame = frame['data'].float() / 255.0  # Normalize (C, H, W)\n",
    "            #print(f\"ğŸ”¹ Orijinal Frame Boyutu: {frame.shape}\")\n",
    "\n",
    "            frame = F.interpolate(frame.unsqueeze(0), size=self.resize_size, mode=\"bilinear\", align_corners=False)\n",
    "            frame = frame.squeeze(0)  # (C, H, W)\n",
    "            #print(f\"ğŸŸ¡ Resize SonrasÄ± Boyut: {frame.shape}\")\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) >= num_frames:\n",
    "                break\n",
    "\n",
    "        # EÄŸer video kÄ±sa ise son frame ile tamamla\n",
    "        while len(frames) < num_frames:\n",
    "            frames.append(frames[-1].clone())  # Tensor'Ã¼ kopyalayarak ekle\n",
    "\n",
    "        frames = torch.stack(frames)  # Frame'leri birleÅŸtir\n",
    "        frames = frames[:num_frames]  # Sabit sayÄ±da frame al (T, C, H, W)\n",
    "        #print(f\"ğŸ”µ Stack SonrasÄ± Boyut (T, C, H, W): {frames.shape}\")\n",
    "\n",
    "        return frames  # GPU'ya gÃ¶ndermeyi __getitem__ iÃ§inde yapacaÄŸÄ±z"
   ],
   "id": "e0462ad59a40b35f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:46:24.722477Z",
     "start_time": "2025-02-22T11:46:24.711059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = VideoDataset(train_df, num_frames=32)\n",
    "test_dataset = VideoDataset(test_df, num_frames=32)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Train loader {len(train_loader)} batches\")\n",
    "print(f\"Test loader {len(test_loader)} batches\")"
   ],
   "id": "22ce79d5c294f2c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader 139 batches\n",
      "Test loader 35 batches\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "X3D modelimizin output layerini tÃ¼m classlarÄ±mÄ±zÄ± kapsayacak ÅŸekilde arttÄ±rmamÄ±z lazÄ±m\n",
    "Son katman ise ResNetBasicHead altÄ±nda proj olarak tanÄ±mlanmÄ±ÅŸ."
   ],
   "id": "49f69497b15dc01f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:46:26.156357Z",
     "start_time": "2025-02-22T11:46:24.736007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "# âœ… X3D Modelini YÃ¼kleme\n",
    "model_name = \"x3d_xs\"\n",
    "base_model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)\n",
    "\n",
    "# âœ… **Ã‡Ä±kÄ±ÅŸ KatmanlarÄ±nÄ± GÃ¼ncelle**\n",
    "in_features = base_model.blocks[-1].proj.out_features  # âœ… **DoÄŸru Ã§Ä±kÄ±ÅŸÄ± al!** (400 olmalÄ±)\n",
    "\n",
    "binary_head = nn.Linear(2048, 1)  # Binary sÄ±nÄ±flandÄ±rma iÃ§in Sigmoid\n",
    "multi_head = nn.Linear(2048, len(train_df[\"multi_label\"].unique()))  # Multi-class sÄ±nÄ±flandÄ±rma\n",
    "\n",
    "# âœ… **MultiTaskX3D Modeli**\n",
    "class MultiTaskX3D(nn.Module):\n",
    "    def __init__(self, base_model, binary_head, multi_head):\n",
    "        super(MultiTaskX3D, self).__init__()\n",
    "\n",
    "        # **Feature Extractor - Son bloÄŸun iÃ§indeki ProjectedPool eklendi!**\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            *base_model.blocks[:-1],\n",
    "            base_model.blocks[-1].pool  # âœ… **Burada 400'e dÃ¶nÃ¼ÅŸÃ¼m saÄŸlandÄ±!**\n",
    "        )\n",
    "\n",
    "        # **Global Average Pooling - TÃ¼m boyutlarÄ± 1x1x1'e dÃ¼ÅŸÃ¼rÃ¼yor!**\n",
    "        self.gap = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "        # **Flatten**\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # **Ã‡Ä±kÄ±ÅŸ KatmanlarÄ±**\n",
    "        self.binary_head = binary_head\n",
    "        self.binary_activation = nn.Sigmoid()\n",
    "\n",
    "        self.multi_head = multi_head\n",
    "        self.multi_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f\"ğŸš€ Model GiriÅŸi: {x.shape}\")\n",
    "\n",
    "        x = self.feature_extractor(x)\n",
    "        #print(f\"ğŸŸ¡ Feature Extractor Ã‡Ä±kÄ±ÅŸÄ±: {x.shape}\")  # **(16, 400, 1, 1, 1) olmalÄ±!**\n",
    "\n",
    "        x = self.gap(x)  # âœ… **GAP ile (16, 400, 1, 1, 1)**\n",
    "        #print(f\"ğŸ”µ GAP SonrasÄ± Boyut: {x.shape}\")\n",
    "\n",
    "        x = self.flatten(x)  # âœ… **ArtÄ±k (16, 400) olmasÄ± lazÄ±m!**\n",
    "        #print(f\"ğŸŸ¢ Flatten SonrasÄ± Boyut: {x.shape}\")\n",
    "\n",
    "        binary_out = self.binary_head(x)  # Binary sÄ±nÄ±flandÄ±rma\n",
    "        multi_out = self.multi_activation(self.multi_head(x))  # Multi-class sÄ±nÄ±flandÄ±rma\n",
    "\n",
    "        return binary_out, multi_out\n",
    "\n",
    "# âœ… Modeli baÅŸlat\n",
    "model = MultiTaskX3D(base_model, binary_head, multi_head)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"ğŸš€ Model baÅŸarÄ±yla yÃ¼klendi! Ã‡alÄ±ÅŸtÄ±rÄ±lan cihaz: {device}\")"
   ],
   "id": "eb2055b4174b845f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Bugra/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Model baÅŸarÄ±yla yÃ¼klendi! Ã‡alÄ±ÅŸtÄ±rÄ±lan cihaz: cuda\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import torch\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "dummy_input = torch.randn(1, 3, 16, 160, 160)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"x3d_xs.onnx\", opset_version=11\n",
    "                  ,do_constant_folding=True, input_names=[\"input\"], output_names=[\"output\"])"
   ],
   "id": "cf0f8ab8e20aa3b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:20:55.814874Z",
     "start_time": "2025-02-22T11:46:26.188132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "# ğŸ¯ Loss & Optimizer\n",
    "criterion_binary = nn.BCEWithLogitsLoss()  # Binary classification iÃ§in\n",
    "criterion_multi = nn.CrossEntropyLoss()  # Multi-class classification iÃ§in\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)  # Weight decay ile overfitting azaltÄ±lÄ±r\n",
    "\n",
    "# âš¡ AMP (Automatic Mixed Precision)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# ğŸ›‘ Early Stopping Parametreleri\n",
    "patience = 3  # KaÃ§ epoch boyunca iyileÅŸme olmazsa durdursun\n",
    "min_delta = 0.01  # Ä°yileÅŸme iÃ§in gereken minimum fark\n",
    "best_loss = float(\"inf\")  # En iyi validation loss baÅŸta sonsuz olarak ayarlanÄ±r\n",
    "counter = 0  # Ä°yileÅŸme olmayan epoch sayÄ±sÄ±\n",
    "accuracy_threshold = 85.0  # Accuracy'nin geÃ§mesi gereken eÅŸik\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for epoch in range(40):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for videos, binary_labels, multi_labels in train_loader:\n",
    "        videos, binary_labels, multi_labels = (\n",
    "            videos.to(device),\n",
    "            binary_labels.to(device).float(),\n",
    "            multi_labels.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast(device):\n",
    "            binary_out, multi_out = model(videos)\n",
    "\n",
    "            # ğŸŸ¢ Binary Classification Loss (Sigmoid)\n",
    "            binary_loss = criterion_binary(binary_out.squeeze(), binary_labels)\n",
    "\n",
    "            # ğŸ”´ Multi-Class Classification Loss (Softmax) â†’ Sadece anormal olanlara uygula\n",
    "            mask = (binary_labels == 1)\n",
    "            if mask.sum() > 0:\n",
    "                multi_loss = criterion_multi(multi_out[mask], multi_labels[mask])\n",
    "            else:\n",
    "                multi_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "            # âœ… Toplam loss hesapla (Binary + Multi)\n",
    "            total_loss = binary_loss + multi_loss\n",
    "\n",
    "        scaler.scale(total_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += total_loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ğŸ“Œ VALIDATION AÅAMASI\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_binary = 0\n",
    "    correct_multi = 0\n",
    "    total_binary = 0\n",
    "    total_multi = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for videos, binary_labels, multi_labels in test_loader:\n",
    "            videos, binary_labels, multi_labels = (\n",
    "                videos.to(device),\n",
    "                binary_labels.to(device).float(),\n",
    "                multi_labels.to(device),\n",
    "            )\n",
    "\n",
    "            binary_out, multi_out = model(videos)\n",
    "\n",
    "            # âœ… Binary Accuracy (Normal mi, Anormal mi?)\n",
    "            pred_binary = (binary_out.squeeze() > 0.5).long()\n",
    "            correct_binary += (pred_binary == binary_labels).sum().item()\n",
    "            total_binary += binary_labels.size(0)\n",
    "\n",
    "            # âœ… Multi-Class Accuracy (EÄŸer anormalse hangi sÄ±nÄ±f?)\n",
    "            mask = (binary_labels == 1)\n",
    "            if mask.sum() > 0:\n",
    "                pred_multi = torch.argmax(multi_out[mask], dim=1)\n",
    "                correct_multi += (pred_multi == multi_labels[mask]).sum().item()\n",
    "                total_multi += multi_labels[mask].size(0)\n",
    "\n",
    "            # âœ… Validation loss hesapla\n",
    "            loss = criterion_binary(binary_out.squeeze(), binary_labels)\n",
    "            if total_multi > 0:\n",
    "                loss += criterion_multi(multi_out[mask], multi_labels[mask])\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    binary_acc = 100 * correct_binary / total_binary\n",
    "    multi_acc = 100 * correct_multi / total_multi if total_multi > 0 else 0\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} \"\n",
    "        f\"| Binary Acc: {binary_acc:.2f}% | Multi Acc: {multi_acc:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # âœ… **Early Stopping (Binary Accuracy 85%'i geÃ§meli)**\n",
    "    if binary_acc >= accuracy_threshold:\n",
    "        if best_loss - val_loss > min_delta:\n",
    "            best_loss = val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_epoch_{epoch+1}.pth\")\n",
    "            print(f\"âœ… Model kaydedildi: best_model_epoch_{epoch+1}.pth\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"â— Early stopping counter: {counter}/{patience}\")\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(\"â¹ï¸ Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"ğŸš¨ Accuracy {binary_acc:.2f}% < {accuracy_threshold}%, early stopping devre dÄ±ÅŸÄ±!\")\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            },\n",
    "            f\"checkpoint_{epoch}.pth\",\n",
    "        )\n",
    "        print(f\"Model {epoch + 1} saved to checkpoint_{epoch + 1}.pth\")\n",
    "\n",
    "print(\"âœ… EÄŸitim tamamlandÄ±!\")"
   ],
   "id": "9b297db9945016d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 3.0069 | Val Loss: 2.9461 | Binary Acc: 75.00% | Multi Acc: 19.38%\n",
      "ğŸš¨ Accuracy 75.00% < 85.0%, early stopping devre dÄ±ÅŸÄ±!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
