{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugrakaann/SuspiciousActionRecognition/blob/master/x3dxs_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!pip install pytorchvideo torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFgv3OC86_1G",
        "outputId": "1d8541a7-0400-42a6-91f4-8d4d585eec86"
      },
      "id": "WFgv3OC86_1G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorchvideo\n",
            "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/132.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting fvcore (from pytorchvideo)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av (from pytorchvideo)\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting parameterized (from pytorchvideo)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting iopath (from pytorchvideo)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (3.0.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Collecting portalocker (from iopath->pytorchvideo)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188686 sha256=13c72a5bacdcdf209cb564915d032aea384e5c8b797caf1a727139092e9c8280\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/6d/ae/d016375a73be141a0e11bb42289e2d0b046c35687fc8010ecc\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=4395f98995c371c26d26f8a952d53f3ae3f3d3d0ef06f014138feeff2ed7c0a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=0a0fd98b8c356ca4bdc9c1e333cf953ca228128a4ef785454e165847c4b5826a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, parameterized, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, av, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, nvidia-cusolver-cu12, fvcore, pytorchvideo\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed av-14.3.0 fvcore-0.1.5.post20221221 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 parameterized-0.9.0 portalocker-3.1.1 pytorchvideo-0.1.5 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:22.236707Z",
          "start_time": "2025-02-22T11:46:16.336297Z"
        },
        "id": "aea6d8027b7de87f"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np"
      ],
      "id": "aea6d8027b7de87f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T12:45:17.298142Z",
          "start_time": "2025-02-22T12:45:16.394712Z"
        },
        "id": "d450b013940b2438",
        "outputId": "2227a80b-ce15-46fc-d9c0-3c2f891cc630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "file_id = '1TNnf9zzoreiF7qaWZFjRXEDejThIbXJe'\n",
        "url = f\"https://drive.google.com/uc?export=download&confirm=t&id={file_id}\"\n",
        "\n",
        "# DosyayÄ± indir\n",
        "output_path = '/content/sample_data/dataset.zip'\n",
        "gdown.download(url, output_path, quiet=False)\n",
        "\n",
        "# DosyayÄ± unzip yap\n",
        "with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/sample_data')\n",
        "\n",
        "print(\"Dosya baÅŸarÄ±yla indirildi ve Ã§Ä±karÄ±ldÄ±.\")"
      ],
      "id": "d450b013940b2438",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=t&id=1TNnf9zzoreiF7qaWZFjRXEDejThIbXJe\n",
            "To: /content/sample_data/dataset.zip\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.3G/10.3G [02:33<00:00, 67.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dosya baÅŸarÄ±yla indirildi ve Ã§Ä±karÄ±ldÄ±.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T12:45:17.315483800Z",
          "start_time": "2025-02-22T11:46:22.239686Z"
        },
        "id": "8be6ceab98346e92"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ğŸ”¥ Ana dataset klasÃ¶rÃ¼\n",
        "dataset_path = \"/content/sample_data/dataset/Videos/Videos/\"\n",
        "\n",
        "# ğŸ“Œ Normal ve Abnormal klasÃ¶rlerini al\n",
        "normal_path = os.path.normpath(os.path.join(dataset_path, \"normal\"))\n",
        "abnormal_path = os.path.normpath(os.path.join(dataset_path, \"abnormal\"))\n",
        "\n",
        "# ğŸ“Œ TÃ¼m abnormal sÄ±nÄ±flarÄ± al\n",
        "abnormal_classes = [folder for folder in os.listdir(abnormal_path) if os.path.isdir(os.path.join(abnormal_path, folder))]\n",
        "class_to_index = {cls: idx for idx, cls in enumerate(abnormal_classes, start=1)}  # 1, 2, 3... (Abnormal sÄ±nÄ±flar)\n",
        "\n",
        "# ğŸ“Œ DataFrame oluÅŸturmak iÃ§in liste\n",
        "data = []\n",
        "\n",
        "# âœ… Normal videolar (Binary = 0, Multi = -1)\n",
        "for subfolder in os.listdir(normal_path):\n",
        "    subfolder_path = os.path.normpath(os.path.join(normal_path, subfolder))\n",
        "\n",
        "    if os.path.isdir(subfolder_path):  # EÄŸer bir klasÃ¶rse\n",
        "        videos = [\n",
        "            os.path.normpath(os.path.join(subfolder_path, v)).replace(\"\\\\\", \"/\")  # Windows uyumu iÃ§in dÃ¼zeltilmiÅŸ\n",
        "            for v in os.listdir(subfolder_path) if v.endswith(('.mp4', '.avi', '.mov'))\n",
        "        ]\n",
        "        for video in videos:\n",
        "            data.append((video, \"normal\", 0, -1))  # Binary label = 0, Multi label = -1 (yok)\n",
        "\n",
        "# âœ… Anormal videolar (Binary = 1, Multi = class index)\n",
        "for subfolder in abnormal_classes:\n",
        "    subfolder_path = os.path.normpath(os.path.join(abnormal_path, subfolder))\n",
        "\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # RekÃ¼rsif olarak tÃ¼m alt klasÃ¶rleri gezer\n",
        "        for root, dirs, files in os.walk(subfolder_path):\n",
        "            for file in files:\n",
        "                if file.endswith(('.mp4', '.avi', '.mov')):\n",
        "                    video_path = os.path.normpath(os.path.join(root, file)).replace(\"\\\\\", \"/\")\n",
        "                    # Burada 'subfolder' en Ã¼st dÃ¼zey klasÃ¶r adÄ±nÄ± temsil eder;\n",
        "                    # eÄŸer alt klasÃ¶rlere gÃ¶re farklÄ± etiket atamak isterseniz, root veya dosya adÄ±nÄ± parse edebilirsiniz.\n",
        "                    data.append((video_path, subfolder, 1, class_to_index.get(subfolder, -1)))\n",
        "\n",
        "# ğŸ”¥ DataFrame oluÅŸtur\n",
        "df = pd.DataFrame(data, columns=[\"video_path\", \"category\", \"binary_label\", \"multi_label\"])\n"
      ],
      "id": "8be6ceab98346e92",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:22.392226Z",
          "start_time": "2025-02-22T11:46:22.382103Z"
        },
        "id": "ffc00782cc50e573",
        "outputId": "8c940fef-e659-47d5-82f0-098324430ee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2,stratify=df[\"binary_label\"],random_state=42)\n",
        "\n",
        "print(f\"Train set {len(train_df)} videos\")\n",
        "print(f\"Test set {len(test_df)} videos\")"
      ],
      "id": "ffc00782cc50e573",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set 2603 videos\n",
            "Test set 651 videos\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# GPU kullanÄ±mÄ±nÄ± kontrol et\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    print(\"GPU bulunuyor:\", physical_devices)\n",
        "else:\n",
        "    print(\"GPU bulunamadÄ±.\")\n"
      ],
      "metadata": {
        "id": "xQH8ia_uBS1E",
        "outputId": "90426c38-a757-43df-a222-602aaeab4ff7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xQH8ia_uBS1E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU bulunuyor: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.15.0"
      ],
      "metadata": {
        "id": "wkpeQsHERg6u"
      },
      "id": "wkpeQsHERg6u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Reshape, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Tensorflow session'u temizle (Ã¶nceki iÅŸlemlerden kalanlarÄ± sÄ±fÄ±rla)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# GPU kullanÄ±mÄ±nÄ± devre dÄ±ÅŸÄ± bÄ±rakma\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, False)  # GPU'yu devre dÄ±ÅŸÄ± bÄ±rakÄ±yoruz\n",
        "        print(\"GPU devre dÄ±ÅŸÄ± bÄ±rakÄ±ldÄ±.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU ayarlanÄ±rken hata oluÅŸtu: {e}\")\n",
        "else:\n",
        "    print(\"GPU bulunamadÄ±, CPU kullanÄ±lacak.\")\n",
        "\n",
        "# Tensorflow'un CUDA ile derlenip derlenmediÄŸini ve fiziksel GPU olup olmadÄ±ÄŸÄ±nÄ± gÃ¶ster\n",
        "print(\"TensorFlow CUDA destekli mi?:\", tf.test.is_built_with_cuda())\n",
        "print(\"Fiziksel GPU var mÄ±?:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "\n",
        "def build_autoencoder(input_shape):\n",
        "    # Input shape: (height, width, channels)\n",
        "    input_img = Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "    # Encoder kÄ±smÄ±\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Temporal Ã¶zellikler iÃ§in 1x1 konvolÃ¼syon kullanÄ±n\n",
        "    temporal_features = Conv2D(16, (1, 1), activation='relu')(encoded)\n",
        "\n",
        "    # Decoder kÄ±smÄ±\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(temporal_features)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    # Ã‡Ä±kÄ±ÅŸ - orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ yeniden oluÅŸtur\n",
        "    decoded = Conv2D(input_shape[2], (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Model tanÄ±mÄ±\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "# Frame yÃ¼kleme fonksiyonu - GPU iÃ§in optimize edilmiÅŸ\n",
        "def load_frames_from_videos(folder, target_size, frame_interval=30):\n",
        "    frames = []\n",
        "    valid_extensions = ('.mp4', '.avi', '.mkv')\n",
        "\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for filename in sorted(files):\n",
        "            if not filename.lower().endswith(valid_extensions):\n",
        "                continue\n",
        "\n",
        "            video_path = os.path.join(root, filename)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frame_idx = 0\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "            with tqdm(total=total_frames, desc=f\"Ä°ÅŸleniyor: {filename}\", leave=False) as pbar:\n",
        "                while cap.isOpened():\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret:\n",
        "                        break\n",
        "\n",
        "                    if frame_idx % frame_interval == 0:\n",
        "                        frame_resized = cv2.resize(frame, target_size)\n",
        "                        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "                        frames.append(frame_rgb)\n",
        "\n",
        "                    frame_idx += 1\n",
        "                    pbar.update(1)\n",
        "\n",
        "            cap.release()\n",
        "            tqdm.write(f\"{filename} dosyasÄ±ndan {frame_idx // frame_interval} kare Ã§ekildi.\")\n",
        "\n",
        "    if len(frames) == 0:\n",
        "        raise ValueError(f\"'{folder}' klasÃ¶rÃ¼nde geÃ§erli video dosyasÄ± bulunamadÄ±.\")\n",
        "\n",
        "    # GPU iÃ§in optimize edilmiÅŸ veri hazÄ±rlama\n",
        "    frames = np.stack(frames, axis=0).astype('float32') / 255.0\n",
        "    return frames\n",
        "\n",
        "\n",
        "# EÄŸitim fonksiyonu\n",
        "def train_autoencoder(normal_videos_folder, target_size=(128, 128), batch_size=32, epochs=50):\n",
        "    # Veri yÃ¼kleme\n",
        "    print(\"Normal videolardan frame'ler yÃ¼kleniyor...\")\n",
        "    normal_frames = load_frames_from_videos(normal_videos_folder, target_size)\n",
        "    print(f\"Toplam {len(normal_frames)} frame yÃ¼klendi.\")\n",
        "\n",
        "    # Model oluÅŸturma\n",
        "    input_shape = (target_size[1], target_size[0], 3)\n",
        "    autoencoder = build_autoencoder(input_shape)\n",
        "    autoencoder.summary()\n",
        "\n",
        "    # ModelCheckpoint Callback\n",
        "    checkpoint_dir = '/content/drive/MyDrive/modelepochsaves/'\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-6\n",
        "        ),\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_epoch_end=lambda epoch, logs: autoencoder.save(\n",
        "                f'{checkpoint_dir}autoencoder_epoch_{epoch+1}'  # Epoch sayÄ±sÄ± eklenmiÅŸ dosya adÄ±\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # EÄŸitim\n",
        "    print(\"Autoencoder eÄŸitimi baÅŸlÄ±yor...\")\n",
        "    history = autoencoder.fit(\n",
        "        normal_frames, normal_frames,\n",
        "        validation_split=0.1,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return autoencoder, history\n",
        "\n",
        "\n",
        "# EÄŸitimi baÅŸlat\n",
        "normal_videos_folder = '/content/sample_data/dataset/Videos/Videos/normal'\n",
        "autoencoder, history = train_autoencoder(normal_videos_folder)\n",
        "\n",
        "# EÄŸitim sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtir\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Modeli kaydet\n",
        "autoencoder.save('/content/drive/MyDrive/modelepochsaves/autoencoder_final')\n",
        "print(\"Model kaydedildi: autoencoder_final.h5\")\n"
      ],
      "metadata": {
        "id": "sOc8Qm8MLzeJ",
        "outputId": "25a81fa7-d0b5-4253-9707-182c7fe23d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "sOc8Qm8MLzeJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU bulundu ve memory growth aktif: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow CUDA destekli mi?: True\n",
            "Fiziksel GPU var mÄ±?: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow version: 2.18.0\n",
            "Num GPUs Available:  1\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "TensorFlow version: 2.18.0\n",
            "TensorFlow built with CUDA: True\n",
            "TensorFlow built with ROCm: False\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "CUDA support: True\n",
            "\n",
            "===== Nvidia-SMI Ã‡Ä±kÄ±ÅŸÄ± =====\n",
            "Sun Apr 27 18:14:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0             30W /   70W |    4204MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "===== CUDA ve cuDNN VersiyonlarÄ± =====\n",
            "CUDA Version: nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "cuDNN Version Info:\n",
            " #define CUDNN_MAJOR 9\n",
            "#define CUDNN_MINOR 2\n",
            "#define CUDNN_PATCHLEVEL 1\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 10000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "/* cannot use constexpr here since this is a C-only file */\n",
            "\n",
            "===== TensorFlow Build Info =====\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow.python.platform.build_info' has no attribute 'cuda_version_number'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1e62b05462b3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_info\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_build_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n===== TensorFlow Build Info =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA Version TF expects:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_build_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda_version_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuDNN Version TF expects:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_build_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_version_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.platform.build_info' has no attribute 'cuda_version_number'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "frame_transform = T.Compose([\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomRotation(degrees=(-10, 10)),\n",
        "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
        "    T.RandomApply([T.GaussianBlur(3)], p=0.3),\n",
        "    T.RandomApply([T.RandomGrayscale(p=0.2)], p=0.2),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "nTB7UP8sJxAq"
      },
      "id": "nTB7UP8sJxAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def frame_dropout(frames, p=0.2):\n",
        "    \"\"\"Belirli bir ihtimalle rastgele kareleri dÃ¼ÅŸÃ¼r.\"\"\"\n",
        "    keep_mask = torch.rand(len(frames)) > p\n",
        "    return frames[keep_mask] if keep_mask.sum() > 0 else frames\n",
        "\n",
        "def speed_perturbation(frames, min_speed=0.8, max_speed=1.2):\n",
        "    \"\"\"Videoyu rastgele hÄ±zlandÄ±r veya yavaÅŸlat.\"\"\"\n",
        "    speed_factor = torch.FloatTensor(1).uniform_(min_speed, max_speed).item()\n",
        "    indices = torch.linspace(0, len(frames)-1, int(len(frames) * speed_factor)).long()\n",
        "    return frames[indices]"
      ],
      "metadata": {
        "id": "Ltf1G3_QJ6WJ"
      },
      "id": "Ltf1G3_QJ6WJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixes frame count after applying frame dropout at augmentation\n",
        "\n",
        "def fix_frame_count(frames, target_num_frames):\n",
        "    \"\"\"Frame sayÄ±sÄ±nÄ± sabitler: EÄŸer fazla ise kÄ±rpar, eksikse tekrarlar.\"\"\"\n",
        "    num_frames = frames.shape[0]  # Frame sayÄ±sÄ±nÄ± al\n",
        "\n",
        "    if num_frames > target_num_frames:\n",
        "        frames = frames[:target_num_frames]  # Fazla olanlarÄ± kÄ±rp\n",
        "    elif num_frames < target_num_frames:\n",
        "        repeat_frames = target_num_frames - num_frames\n",
        "        last_frame = frames[-1].unsqueeze(0).repeat(repeat_frames, 1, 1, 1)  # Eksik frame'leri tekrar et\n",
        "        frames = torch.cat([frames, last_frame], dim=0)\n",
        "\n",
        "    return frames  # Her durumda (T, C, H, W) dÃ¶ner"
      ],
      "metadata": {
        "id": "Mc-L1wrgNvlu"
      },
      "id": "Mc-L1wrgNvlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:24.711059Z",
          "start_time": "2025-02-22T11:46:22.415593Z"
        },
        "id": "e0462ad59a40b35f"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, df, optical_flow_csv, num_frames=8, transform=None, resize_size=(192, 192), mode= \"train\"):\n",
        "        self.df = df\n",
        "        self.optical_flow_data = pd.read_csv(optical_flow_csv)  # ğŸ“Œ Optical Flow verileri\n",
        "        self.num_frames = num_frames\n",
        "        self.transform = transform\n",
        "        self.resize_size = resize_size\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.df.iloc[idx][\"video_path\"]\n",
        "        binary_label = self.df.iloc[idx][\"binary_label\"]\n",
        "        multi_label = self.df.iloc[idx][\"multi_label\"]\n",
        "\n",
        "        if binary_label == 1:  # **Anormal Video**\n",
        "            # ğŸ“Œ **Ã–nceden hesaplanan en hareketli segmentleri al**\n",
        "            segments = eval(self.optical_flow_data[self.optical_flow_data[\"video_path\"] == video_path][\"top_segments\"].values[0])\n",
        "\n",
        "            # ğŸ“Œ **Rastgele bir hareketli segment seÃ§**\n",
        "            chosen_segment = random.choice(segments)\n",
        "\n",
        "            # ğŸ“Œ **SeÃ§ili segmentin frame'lerini al**\n",
        "            frames = self.extract_frames(video_path, chosen_segment)\n",
        "\n",
        "        else:  # **Normal Video**\n",
        "            frames = self.extract_uniform_frames(video_path, self.num_frames)\n",
        "\n",
        "        frames = fix_frame_count(frames, self.num_frames)\n",
        "\n",
        "        #EÄŸer train setindeysek augmentation uygula\n",
        "        if self.mode == \"train\":\n",
        "            frames = frame_dropout(frames, p=0.1)\n",
        "            frames = speed_perturbation(frames, min_speed=0.8, max_speed=1.2)\n",
        "            frames = torch.stack([frame_transform(frame) for frame in frames])\n",
        "            frames = fix_frame_count(frames,self.num_frames)\n",
        "\n",
        "\n",
        "        # **ğŸ¯ GÄ°RÄ°Å FORMATINI DÃœZELTME**\n",
        "        frames = frames.permute(1, 0, 2, 3).contiguous()  # (T, C, H, W) â†’ (C, T, H, W)\n",
        "\n",
        "        # EÄŸer transform varsa uygula\n",
        "        if self.transform:\n",
        "            frames = self.transform(frames)\n",
        "\n",
        "        return frames, torch.tensor(binary_label, dtype=torch.float32), torch.tensor(multi_label, dtype=torch.long)\n",
        "\n",
        "    def extract_frames(self, video_path, segment_index):\n",
        "        \"\"\"Anormal videolar iÃ§in Optical Flow'a gÃ¶re seÃ§ilen segmentten frame'leri Ã§Ä±karÄ±r.\"\"\"\n",
        "        vr = torchvision.io.VideoReader(video_path, \"video\")\n",
        "        vr.set_current_stream(\"video\")\n",
        "\n",
        "        frames = []\n",
        "        frame_count = 0\n",
        "        start_frame = segment_index  # ğŸ“Œ SeÃ§ilen hareketli segmentin baÅŸlangÄ±cÄ±\n",
        "        end_frame = start_frame + self.num_frames\n",
        "\n",
        "        for i, frame in enumerate(vr):\n",
        "            if i < start_frame:\n",
        "                continue  # ğŸ“Œ SeÃ§ilen segmentin baÅŸlangÄ±cÄ±na kadar frame'leri atla\n",
        "\n",
        "            if i >= end_frame:\n",
        "                break  # ğŸ“Œ SeÃ§ilen segment tamamlandÄ±ktan sonra Ã§Ä±k\n",
        "\n",
        "            frame = frame['data'].float() / 255.0  # Normalize (C, H, W)\n",
        "            frame = F.interpolate(frame.unsqueeze(0), size=self.resize_size, mode=\"bilinear\", align_corners=False)\n",
        "            frames.append(frame.squeeze(0))\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        return torch.stack(frames)  # (T, C, H, W) olarak dÃ¶ndÃ¼r\n",
        "\n",
        "    def extract_uniform_frames(self, video_path, num_frames):\n",
        "        \"\"\"Normal videolar iÃ§in eÅŸit aralÄ±klarla frame seÃ§er.\"\"\"\n",
        "        vr = torchvision.io.VideoReader(video_path, \"video\")\n",
        "        vr.set_current_stream(\"video\")\n",
        "\n",
        "        frames = []\n",
        "        for frame in vr:\n",
        "            frame = frame['data'].float() / 255.0  # Normalize (C, H, W)\n",
        "            frame = F.interpolate(frame.unsqueeze(0), size=self.resize_size, mode=\"bilinear\", align_corners=False)\n",
        "            frames.append(frame.squeeze(0))\n",
        "\n",
        "        total_frames = len(frames)\n",
        "\n",
        "        # EÄŸer video kÄ±sa ise, son frame ile doldur\n",
        "        if total_frames < num_frames:\n",
        "            while len(frames) < num_frames:\n",
        "                frames.append(frames[-1].clone())\n",
        "        else:\n",
        "            # ğŸ“Œ **Frame'leri eÅŸit aralÄ±klarla seÃ§**\n",
        "            index_list = torch.linspace(0, total_frames - 1, num_frames).long()\n",
        "            frames = [frames[i] for i in index_list]\n",
        "\n",
        "        return torch.stack(frames)  # (T, C, H, W)"
      ],
      "id": "e0462ad59a40b35f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:24.722477Z",
          "start_time": "2025-02-22T11:46:24.711059Z"
        },
        "id": "22ce79d5c294f2c6",
        "outputId": "27785bf8-abe0-47b9-92a7-2b81b0041759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = VideoDataset(train_df, \"/content/drive/MyDrive/modelepochsaves/optical_flow_segments.csv\", num_frames=48, mode=\"train\")\n",
        "test_dataset = VideoDataset(test_df, \"/content/drive/MyDrive/modelepochsaves/optical_flow_segments.csv\", num_frames=48, mode=\"test\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "print(f\"Train loader {len(train_loader)} batches\")\n",
        "print(f\"Test loader {len(test_loader)} batches\")"
      ],
      "id": "22ce79d5c294f2c6",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader 326 batches\n",
            "Test loader 82 batches\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "49f69497b15dc01f"
      },
      "cell_type": "markdown",
      "source": [
        "X3D modelimizin output layerini tÃ¼m classlarÄ±mÄ±zÄ± kapsayacak ÅŸekilde arttÄ±rmamÄ±z lazÄ±m\n",
        "Son katman ise ResNetBasicHead altÄ±nda proj olarak tanÄ±mlanmÄ±ÅŸ."
      ],
      "id": "49f69497b15dc01f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T11:46:26.156357Z",
          "start_time": "2025-02-22T11:46:24.736007Z"
        },
        "id": "eb2055b4174b845f",
        "outputId": "81c53360-6575-424a-c793-a5740c6e7008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "# âœ… X3D Modelini YÃ¼kleme\n",
        "model_name = \"x3d_s\"\n",
        "base_model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)\n",
        "\n",
        "# âœ… **Ã‡Ä±kÄ±ÅŸ KatmanlarÄ±nÄ± GÃ¼ncelle**\n",
        "in_features = base_model.blocks[-1].proj.out_features  # âœ… **DoÄŸru Ã§Ä±kÄ±ÅŸÄ± al!** (400 olmalÄ±)\n",
        "\n",
        "binary_head = nn.Linear(2048, 1)  # Binary sÄ±nÄ±flandÄ±rma iÃ§in Sigmoid\n",
        "multi_head = nn.Linear(2048, len(train_df[\"multi_label\"].unique()))  # Multi-class sÄ±nÄ±flandÄ±rma\n",
        "\n",
        "# âœ… **MultiTaskX3D Modeli**\n",
        "class MultiTaskX3D(nn.Module):\n",
        "    def __init__(self, base_model, binary_head, multi_head):\n",
        "        super(MultiTaskX3D, self).__init__()\n",
        "\n",
        "        # **Feature Extractor - Son bloÄŸun iÃ§indeki ProjectedPool eklendi!**\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            *base_model.blocks[:-1],\n",
        "            base_model.blocks[-1].pool  # âœ… **Burada 400'e dÃ¶nÃ¼ÅŸÃ¼m saÄŸlandÄ±!**\n",
        "        )\n",
        "\n",
        "        # **Global Average Pooling - TÃ¼m boyutlarÄ± 1x1x1'e dÃ¼ÅŸÃ¼rÃ¼yor!**\n",
        "        self.gap = nn.AdaptiveAvgPool3d(1)\n",
        "\n",
        "        # **Flatten**\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # **Ã‡Ä±kÄ±ÅŸ KatmanlarÄ±**\n",
        "        self.binary_head = binary_head\n",
        "        self.binary_activation = nn.Sigmoid()\n",
        "\n",
        "        self.multi_head = multi_head\n",
        "        self.multi_activation = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(f\"ğŸš€ Model GiriÅŸi: {x.shape}\")\n",
        "\n",
        "        x = self.feature_extractor(x)\n",
        "        #print(f\"ğŸŸ¡ Feature Extractor Ã‡Ä±kÄ±ÅŸÄ±: {x.shape}\")  # **(16, 400, 1, 1, 1) olmalÄ±!**\n",
        "\n",
        "        x = self.gap(x)  # âœ… **GAP ile (16, 400, 1, 1, 1)**\n",
        "        #print(f\"ğŸ”µ GAP SonrasÄ± Boyut: {x.shape}\")\n",
        "\n",
        "        x = self.flatten(x)  # âœ… **ArtÄ±k (16, 400) olmasÄ± lazÄ±m!**\n",
        "        #print(f\"ğŸŸ¢ Flatten SonrasÄ± Boyut: {x.shape}\")\n",
        "\n",
        "        binary_out = self.binary_head(x)  # Binary sÄ±nÄ±flandÄ±rma\n",
        "        multi_out = self.multi_activation(self.multi_head(x))  # Multi-class sÄ±nÄ±flandÄ±rma\n",
        "\n",
        "        return binary_out, multi_out\n",
        "\n",
        "# âœ… Modeli baÅŸlat\n",
        "model = MultiTaskX3D(base_model, binary_head, multi_head)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"ğŸš€ Model baÅŸarÄ±yla yÃ¼klendi! Ã‡alÄ±ÅŸtÄ±rÄ±lan cihaz: {device}\")"
      ],
      "id": "eb2055b4174b845f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/pytorchvideo/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/X3D_S.pyth\" to /root/.cache/torch/hub/checkpoints/X3D_S.pyth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.4M/29.4M [00:00<00:00, 38.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Model baÅŸarÄ±yla yÃ¼klendi! Ã‡alÄ±ÅŸtÄ±rÄ±lan cihaz: cuda\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cf0f8ab8e20aa3b7"
      },
      "cell_type": "markdown",
      "source": [
        "import torch\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "dummy_input = torch.randn(1, 3, 16, 160, 160)\n",
        "\n",
        "torch.onnx.export(model, dummy_input, \"x3d_xs.onnx\", opset_version=11\n",
        "                  ,do_constant_folding=True, input_names=[\"input\"], output_names=[\"output\"])"
      ],
      "id": "cf0f8ab8e20aa3b7"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self,inputs,targets):\n",
        "        ce_loss = F.cross_entropy(inputs,targets,reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return focal_loss.mean()"
      ],
      "metadata": {
        "id": "pZxmxvCalU2T"
      },
      "id": "pZxmxvCalU2T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-22T12:20:55.814874Z",
          "start_time": "2025-02-22T11:46:26.188132Z"
        },
        "id": "9b297db9945016d9",
        "outputId": "1ab45868-d72e-4e68-d1e3-69eae0ffe0e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "epoch_file_location = \"/content/drive/MyDrive/modelepochsaves\"\n",
        "\n",
        "# ğŸ¯ Loss & Optimizer\n",
        "criterion_binary = nn.BCEWithLogitsLoss()  # Binary classification iÃ§in\n",
        "criterion_multi = FocalLoss()  # Multi-class classification iÃ§in\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-2)  # Weight decay ile overfitting azaltÄ±lÄ±r\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "# âš¡ AMP (Automatic Mixed Precision)\n",
        "scaler = torch.amp.GradScaler()\n",
        "\n",
        "# ğŸ›‘ Early Stopping Parametreleri\n",
        "patience = 3  # KaÃ§ epoch boyunca iyileÅŸme olmazsa durdursun\n",
        "min_delta = 0.01  # Ä°yileÅŸme iÃ§in gereken minimum fark\n",
        "best_loss = float(\"inf\")  # En iyi validation loss baÅŸta sonsuz olarak ayarlanÄ±r\n",
        "counter = 0  # Ä°yileÅŸme olmayan epoch sayÄ±sÄ±\n",
        "accuracy_threshold = 85.0  # Accuracy'nin geÃ§mesi gereken eÅŸik\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for epoch in range(40):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for videos, binary_labels, multi_labels in train_loader:\n",
        "        videos, binary_labels, multi_labels = (\n",
        "            videos.to(device),\n",
        "            binary_labels.to(device).float(),\n",
        "            multi_labels.to(device),\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(device):\n",
        "            binary_out, multi_out = model(videos)\n",
        "\n",
        "            # ğŸŸ¢ Binary Classification Loss (Sigmoid)\n",
        "            binary_loss = criterion_binary(binary_out.squeeze(), binary_labels)\n",
        "\n",
        "            # ğŸ”´ Multi-Class Classification Loss (Softmax) â†’ Sadece anormal olanlara uygula\n",
        "            mask = (binary_labels == 1)\n",
        "            if mask.sum() > 0:\n",
        "                multi_loss = criterion_multi(multi_out[mask], multi_labels[mask])\n",
        "            else:\n",
        "                multi_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "            # âœ… Toplam loss hesapla (Binary + Multi)\n",
        "            total_loss = binary_loss + multi_loss\n",
        "\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += total_loss.item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # ğŸ“Œ VALIDATION AÅAMASI\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_binary = 0\n",
        "    correct_multi = 0\n",
        "    total_binary = 0\n",
        "    total_multi = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for videos, binary_labels, multi_labels in test_loader:\n",
        "            videos, binary_labels, multi_labels = (\n",
        "                videos.to(device),\n",
        "                binary_labels.to(device).float(),\n",
        "                multi_labels.to(device),\n",
        "            )\n",
        "\n",
        "            binary_out, multi_out = model(videos)\n",
        "\n",
        "            # âœ… Binary Accuracy (Normal mi, Anormal mi?)\n",
        "            pred_binary = (binary_out.squeeze() > 0.5).long()\n",
        "            correct_binary += (pred_binary == binary_labels).sum().item()\n",
        "            total_binary += binary_labels.size(0)\n",
        "\n",
        "            # âœ… Multi-Class Accuracy (EÄŸer anormalse hangi sÄ±nÄ±f?)\n",
        "            mask = (binary_labels == 1)\n",
        "            if mask.sum() > 0:\n",
        "                pred_multi = torch.argmax(multi_out[mask], dim=1)\n",
        "                correct_multi += (pred_multi == multi_labels[mask]).sum().item()\n",
        "                total_multi += multi_labels[mask].size(0)\n",
        "\n",
        "            # âœ… Validation loss hesapla\n",
        "            loss = criterion_binary(binary_out.squeeze(), binary_labels)\n",
        "            if total_multi > 0:\n",
        "                loss += criterion_multi(multi_out[mask], multi_labels[mask])\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    binary_acc = 100 * correct_binary / total_binary\n",
        "    multi_acc = 100 * correct_multi / total_multi if total_multi > 0 else 0\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} \"\n",
        "        f\"| Binary Acc: {binary_acc:.2f}% | Multi Acc: {multi_acc:.2f}%\"\n",
        "    )\n",
        "\n",
        "    # âœ… **Early Stopping (Binary Accuracy 85%'i geÃ§meli)**\n",
        "    if binary_acc >= accuracy_threshold:\n",
        "        if best_loss - val_loss > min_delta:\n",
        "            best_loss = val_loss\n",
        "            counter = 0\n",
        "            torch.save(model.state_dict(), f\"{epoch_file_location}/best_model_epoch_{epoch+1}.pth\")\n",
        "            print(f\"âœ… Model kaydedildi: best_model_epoch_{epoch+1}.pth\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"â— Early stopping counter: {counter}/{patience}\")\n",
        "\n",
        "        if counter >= patience:\n",
        "            print(\"â¹ï¸ Early stopping triggered. Training stopped.\")\n",
        "            break\n",
        "    else:\n",
        "        print(f\"ğŸš¨ Accuracy {binary_acc:.2f}% < {accuracy_threshold}%, early stopping devre dÄ±ÅŸÄ±!\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            },\n",
        "            f\"{epoch_file_location}/checkpoint_{epoch}.pth\",\n",
        "        )\n",
        "        print(f\"Model {epoch + 1} saved to checkpoint_{epoch + 1}.pth\")\n",
        "\n",
        "print(\"âœ… EÄŸitim tamamlandÄ±!\")"
      ],
      "id": "9b297db9945016d9",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.7108 | Val Loss: 0.7181 | Binary Acc: 60.06% | Multi Acc: 48.96%\n",
            "ğŸš¨ Accuracy 60.06% < 85.0%, early stopping devre dÄ±ÅŸÄ±!\n",
            "Epoch 2 | Train Loss: 0.6038 | Val Loss: 0.7167 | Binary Acc: 56.07% | Multi Acc: 53.11%\n",
            "ğŸš¨ Accuracy 56.07% < 85.0%, early stopping devre dÄ±ÅŸÄ±!\n",
            "Epoch 3 | Train Loss: 0.5089 | Val Loss: 0.7046 | Binary Acc: 54.99% | Multi Acc: 54.77%\n",
            "ğŸš¨ Accuracy 54.99% < 85.0%, early stopping devre dÄ±ÅŸÄ±!\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}